{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5366622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9805061b-fe9f-447a-9bda-209f669f5731",
   "metadata": {},
   "source": [
    "## Load Perspective API scores and calculate MaxToxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f12d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_perspective_scores(output_dir, dataset_type):\n",
    "    files = [i for i in os.listdir(output_dir) if i.startswith('perspective_api_all_occupations_all_gens') and i.endswith('.csv')]\n",
    "    print(files)\n",
    "    perspective_scores = pd.concat([pd.read_csv(os.path.join(output_dir,i)) for i in files])\n",
    "    if 'dataset_type' not in perspective_scores.columns:\n",
    "        perspective_scores = perspective_scores.assign(dataset_type = dataset_type)\n",
    "    \n",
    "    perspective_scores['model_name'] = perspective_scores['model_name'].apply(lambda x: x.split('/')[-1].replace('-hf',''))\n",
    "    perspective_scores['prompt_original'] = perspective_scores['prompt']\n",
    "    perspective_scores['prompt'] = perspective_scores['prompt'].apply(lambda x: '_'.join(x.split('_')[:-1]))\n",
    "    perspective_scores = perspective_scores.assign(seed = perspective_scores['prompt_original'].apply(lambda x: x.split('_')[-1]))\n",
    "    \n",
    "    if 'dataset_type' in perspective_scores.columns:\n",
    "        print(perspective_scores[['model_name','dataset_type']].value_counts())\n",
    "    else:\n",
    "        print(perspective_scores['model_name'].value_counts())\n",
    "\n",
    "    return perspective_scores\n",
    "\n",
    "\n",
    "def format_df_agg(df_agg, agg_cols, col, dataset, prompt):\n",
    "    df_agg = df_agg.describe(percentiles=[i / 100 for i in range(5,100,5)]).transpose().iloc[1:,]\n",
    "    df_agg = df_agg[agg_cols]\n",
    "    df_agg.index = df_agg.index.rename('model')\n",
    "    df_agg = df_agg.reset_index()\n",
    "    df_agg = df_agg.assign(score = col, dataset = dataset, prompt = prompt)[['score','dataset', 'prompt', 'model'] + agg_cols]\n",
    "\n",
    "    return df_agg\n",
    "\n",
    "\n",
    "def calc_max_toxicity(perspective_scores):\n",
    "    prompts = perspective_scores['prompt'].unique()\n",
    "    datasets = perspective_scores['dataset_type'].unique()\n",
    "    score_cols = ['TOXICITY']\n",
    "    # score_cols = ['TOXICITY', 'INSULT','IDENTITY_ATTACK','FLIRTATION']\n",
    "    agg_cols = ['mean', 'std', '25%', '50%', '75%', '90%', 'max']\n",
    "    \n",
    "    df_list = []\n",
    "    df_diff_list = []\n",
    "    df_max_id_list = []\n",
    "    for col in tqdm(score_cols):\n",
    "        for dataset in datasets:\n",
    "            for prompt in prompts:\n",
    "                df_agg = perspective_scores[(perspective_scores['prompt'] == prompt) & (perspective_scores['dataset_type'] == dataset)]\n",
    "                df_agg = pd.pivot_table(df_agg, values=col, columns='model_name', index=['filename_prefix','rank','image_set_seed','im_index','prompt_original']).reset_index()\n",
    "                df_agg_max = df_agg.groupby(['filename_prefix','rank','image_set_seed','prompt_original']).agg('max')\n",
    "                df_agg_min = df_agg.groupby(['filename_prefix','rank','image_set_seed','prompt_original']).agg('min')\n",
    "                df_agg_diff = df_agg_max - df_agg_min\n",
    "\n",
    "                df_agg_id_max = df_agg.groupby(['filename_prefix','rank','image_set_seed','prompt_original']).idxmax()\n",
    "                del df_agg_id_max['im_index']\n",
    "                for i in df_agg_id_max.columns:\n",
    "                    df_agg_id_max.loc[:,i] = df_agg_id_max[i].apply(lambda x: df_agg.iloc[int(x)]['im_index'])\n",
    "                df_agg_id_max = df_agg_id_max.reset_index()\n",
    "                df_agg_id_max = df_agg_id_max.assign(score = col, dataset = dataset, prompt = prompt)\n",
    "\n",
    "                df_agg = format_df_agg(df_agg_max, agg_cols, col, dataset, prompt)\n",
    "                df_agg_diff = format_df_agg(df_agg_diff, agg_cols, col, dataset, prompt)\n",
    "                \n",
    "                df_list.append(df_agg)\n",
    "                df_diff_list.append(df_agg_diff)\n",
    "                df_max_id_list.append(df_agg_id_max)\n",
    "\n",
    "    return [pd.concat(df_list), pd.concat(df_diff_list), pd.concat(df_max_id_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36cc9659-b002-4dfe-85a0-0f509a704987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['perspective_api_all_occupations_all_gens_2_prompts_0.csv']\n",
      "model_name              dataset_type   \n",
      "InternVL3-2B            physical_gender    4080\n",
      "Qwen2.5-VL-3B-Instruct  physical_gender    4080\n",
      "SmolVLM2-2.2B-Instruct  physical_gender    4080\n",
      "deepseek-vl2-tiny       physical_gender    4066\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "perspective_scores = load_perspective_scores('outputs_vllm/physical_gender', 'physical_gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d114874-3d9d-459e-8ab3-24a404edd6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n"
     ]
    }
   ],
   "source": [
    "max_toxicity, max_toxicity_diff, max_toxicity_id = calc_max_toxicity(perspective_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd01f83c-766a-4bb5-9f2b-3de706a097e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>dataset</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>90%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOXICITY</td>\n",
       "      <td>physical_gender</td>\n",
       "      <td>keywords_characteristics</td>\n",
       "      <td>InternVL3-2B</td>\n",
       "      <td>0.108920</td>\n",
       "      <td>0.088028</td>\n",
       "      <td>0.038049</td>\n",
       "      <td>0.076481</td>\n",
       "      <td>0.157253</td>\n",
       "      <td>0.253013</td>\n",
       "      <td>0.401485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOXICITY</td>\n",
       "      <td>physical_gender</td>\n",
       "      <td>keywords_characteristics</td>\n",
       "      <td>Qwen2.5-VL-3B-Instruct</td>\n",
       "      <td>0.136902</td>\n",
       "      <td>0.081158</td>\n",
       "      <td>0.065797</td>\n",
       "      <td>0.124336</td>\n",
       "      <td>0.182691</td>\n",
       "      <td>0.241222</td>\n",
       "      <td>0.479008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOXICITY</td>\n",
       "      <td>physical_gender</td>\n",
       "      <td>keywords_characteristics</td>\n",
       "      <td>SmolVLM2-2.2B-Instruct</td>\n",
       "      <td>0.148425</td>\n",
       "      <td>0.107819</td>\n",
       "      <td>0.076877</td>\n",
       "      <td>0.110732</td>\n",
       "      <td>0.177848</td>\n",
       "      <td>0.324406</td>\n",
       "      <td>0.507899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOXICITY</td>\n",
       "      <td>physical_gender</td>\n",
       "      <td>keywords_characteristics</td>\n",
       "      <td>deepseek-vl2-tiny</td>\n",
       "      <td>0.122869</td>\n",
       "      <td>0.095251</td>\n",
       "      <td>0.060187</td>\n",
       "      <td>0.104579</td>\n",
       "      <td>0.151172</td>\n",
       "      <td>0.228699</td>\n",
       "      <td>0.584095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOXICITY</td>\n",
       "      <td>physical_gender</td>\n",
       "      <td>keywords_personality</td>\n",
       "      <td>InternVL3-2B</td>\n",
       "      <td>0.049496</td>\n",
       "      <td>0.043069</td>\n",
       "      <td>0.027413</td>\n",
       "      <td>0.034277</td>\n",
       "      <td>0.048595</td>\n",
       "      <td>0.092493</td>\n",
       "      <td>0.241222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOXICITY</td>\n",
       "      <td>physical_gender</td>\n",
       "      <td>keywords_personality</td>\n",
       "      <td>Qwen2.5-VL-3B-Instruct</td>\n",
       "      <td>0.103557</td>\n",
       "      <td>0.071353</td>\n",
       "      <td>0.038461</td>\n",
       "      <td>0.089143</td>\n",
       "      <td>0.164187</td>\n",
       "      <td>0.193523</td>\n",
       "      <td>0.347574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOXICITY</td>\n",
       "      <td>physical_gender</td>\n",
       "      <td>keywords_personality</td>\n",
       "      <td>SmolVLM2-2.2B-Instruct</td>\n",
       "      <td>0.038136</td>\n",
       "      <td>0.046064</td>\n",
       "      <td>0.021756</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.032451</td>\n",
       "      <td>0.055175</td>\n",
       "      <td>0.381150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOXICITY</td>\n",
       "      <td>physical_gender</td>\n",
       "      <td>keywords_personality</td>\n",
       "      <td>deepseek-vl2-tiny</td>\n",
       "      <td>0.026807</td>\n",
       "      <td>0.021143</td>\n",
       "      <td>0.018786</td>\n",
       "      <td>0.021020</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.037554</td>\n",
       "      <td>0.233071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score          dataset                    prompt   \n",
       "0  TOXICITY  physical_gender  keywords_characteristics  \\\n",
       "1  TOXICITY  physical_gender  keywords_characteristics   \n",
       "2  TOXICITY  physical_gender  keywords_characteristics   \n",
       "3  TOXICITY  physical_gender  keywords_characteristics   \n",
       "0  TOXICITY  physical_gender      keywords_personality   \n",
       "1  TOXICITY  physical_gender      keywords_personality   \n",
       "2  TOXICITY  physical_gender      keywords_personality   \n",
       "3  TOXICITY  physical_gender      keywords_personality   \n",
       "\n",
       "                    model      mean       std       25%       50%       75%   \n",
       "0            InternVL3-2B  0.108920  0.088028  0.038049  0.076481  0.157253  \\\n",
       "1  Qwen2.5-VL-3B-Instruct  0.136902  0.081158  0.065797  0.124336  0.182691   \n",
       "2  SmolVLM2-2.2B-Instruct  0.148425  0.107819  0.076877  0.110732  0.177848   \n",
       "3       deepseek-vl2-tiny  0.122869  0.095251  0.060187  0.104579  0.151172   \n",
       "0            InternVL3-2B  0.049496  0.043069  0.027413  0.034277  0.048595   \n",
       "1  Qwen2.5-VL-3B-Instruct  0.103557  0.071353  0.038461  0.089143  0.164187   \n",
       "2  SmolVLM2-2.2B-Instruct  0.038136  0.046064  0.021756  0.026087  0.032451   \n",
       "3       deepseek-vl2-tiny  0.026807  0.021143  0.018786  0.021020  0.026882   \n",
       "\n",
       "        90%       max  \n",
       "0  0.253013  0.401485  \n",
       "1  0.241222  0.479008  \n",
       "2  0.324406  0.507899  \n",
       "3  0.228699  0.584095  \n",
       "0  0.092493  0.241222  \n",
       "1  0.193523  0.347574  \n",
       "2  0.055175  0.381150  \n",
       "3  0.037554  0.233071  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193c1d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5b97f00-a0e6-468a-9dda-3a87eeae9e39",
   "metadata": {},
   "source": [
    "## Count frequency of competency words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ff245a5-78b7-4441-a6f4-340951d96ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = pd.read_csv('outputs_vllm/physical_gender/generations.csv')\n",
    "generations = generations.assign(text_tokens = generations['keywords_characteristics_0'].str.lower().str.replace(',','').str.replace('.','').str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14e97c8c-b5c0-433f-8634-4a3c63fda3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "competence_tokens = []\n",
    "with open('competency_words.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        competence_tokens.append(line.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8df783ad-c996-4e0d-9764-7d0ea56d4296",
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = generations.assign(competence_words = generations.apply(lambda x: set(x['text_tokens']).intersection(competence_tokens), axis=1))\n",
    "generations = generations.assign(competence_count = generations['competence_words'].str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79a8b1a8-ea8e-4126-b8b3-a5c2ee836faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202080.000000\n",
       "mean          0.953350\n",
       "std           1.273863\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           1.000000\n",
       "75%           1.000000\n",
       "max          15.000000\n",
       "Name: competence_count, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generations['competence_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03b48a-4264-46ae-bf57-41f61a777759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
